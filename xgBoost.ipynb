{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Assume X and Y are your preprocessed features and target values.\n",
    "# For example, you might load them like:\n",
    "# X = np.load('preprocessed_features.npy')\n",
    "# Y = np.load('target_kd_values.npy')\n",
    "\n",
    "# 1. Split data into 70% training and 30% temporary (which will be split into validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "\n",
    "# 2. Split the temporary set equally into 15% validation and 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "# 3. Evaluate different max_depth values using training and validation sets\n",
    "max_depths = [3, 4, 5, 6, 7, 8, 9]\n",
    "val_mae_values = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:absoluteerror',  # Optimize using MAE loss\n",
    "        max_depth=depth,\n",
    "        eval_metric='mae',              # Report MAE during training\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    val_mae_values.append(mae_val)\n",
    "    print(f\"max_depth: {depth}, Validation MAE: {mae_val:.2f}\")\n",
    "\n",
    "# Find best max_depth based on the lowest validation MAE\n",
    "best_index = np.argmin(val_mae_values)\n",
    "best_depth = max_depths[best_index]\n",
    "print(f\"\\nBest max_depth: {best_depth} with Validation MAE: {val_mae_values[best_index]:.2f}\")\n",
    "\n",
    "# 4. Plot Validation MAE vs. max_depth\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(max_depths, val_mae_values, marker='o', linestyle='-')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.title('Validation MAE vs. max_depth for XGBoost Regressor')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. Retrain final model on the combined training + validation data with best max_depth\n",
    "X_train_val = np.concatenate((X_train, X_val), axis=0)\n",
    "y_train_val = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "final_model = xgb.XGBRegressor(\n",
    "    objective='reg:absoluteerror',\n",
    "    max_depth=best_depth,\n",
    "    eval_metric='mae',\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluate the final model on the unseen test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "print(f\"\\nFinal Test MAE: {test_mae:.2f} nM\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
